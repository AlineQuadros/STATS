{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats, linspace\n",
    "from statsmodels.stats import power\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "%matplotlib inline\n",
    "import utils\n",
    "# jupyter lab configs\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STATISTICS (applied to data science)\n",
    "\n",
    "## These exercises are meant to complement the content given in the pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1 - Summary statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement code for the functions below. In each function, make sure you call the function written before. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean():\n",
    "    pass\n",
    "\n",
    "def sum_squares():\n",
    "    pass\n",
    "\n",
    "def mse():\n",
    "    # mean squared error\n",
    "    pass\n",
    "\n",
    "def rmse():\n",
    "    # rooted mean squared error\n",
    "    pass\n",
    "\n",
    "def variance():\n",
    "    pass\n",
    "\n",
    "def std_dev():\n",
    "    pass\n",
    "\n",
    "def std_error():\n",
    "    pass\n",
    "\n",
    "def confidence_95():\n",
    "    pass\n",
    "    \n",
    "def covariance():\n",
    "    pass\n",
    "\n",
    "def coeficient_variation():\n",
    "    pass\n",
    "  \n",
    "def cov():\n",
    "    pass\n",
    "\n",
    "def z_score():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below plots the diagnostic plots **QQ Plots** for two sets of variables, like raw (unstransformed) and transformed data, for comparison. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.compat import lzip\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.stats.api as sms\n",
    "\n",
    "def plot_compare_transformations(raw_data, transformed_data, transformation_used):\n",
    "    fig = plt.figure()\n",
    "    ax1 = fig.add_subplot(211)\n",
    "    prob = stats.probplot(raw_data, dist=stats.norm, plot=ax1)\n",
    "    ax1.set_xlabel('')\n",
    "    ax1.set_title('Probplot against the normal distribution (line) ')\n",
    "    ax2 = fig.add_subplot(212)\n",
    "    prob = stats.probplot(transformed_data, dist=stats.norm, plot=ax2)\n",
    "    ax2.set_title('Probplot after ' + transformation_used + ' transformation')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: \n",
    "Try **box-cox** (available in **scipy**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate some data with noise\n",
    "raw_data = stats.loggamma.rvs(5, size=100) + 20\n",
    "# apply box-cox\n",
    "transformed_data, _ = stats.boxcox(raw_data)\n",
    "# plot and compare \n",
    "plot_compare_transformations(raw_data, transformed_data, 'box-cox')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see the same effect in numbers:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example with shapiro's test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test of normal distribution with Shapiros Test')\n",
    "print('stat:', stats.shapiro(raw_data)[0],'p-value:', stats.shapiro(raw_data)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test of normal distribution with Shapiros Test')\n",
    "print('stat:', stats.shapiro(transformed_data)[0],'p-value:', stats.shapiro(transformed_data)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = ['Jarque-Bera', 'Chi^2 two-tail prob.', 'Skew', 'Kurtosis']\n",
    "test = sms.jarque_bera(raw_data)\n",
    "lzip(name, test)\n",
    "test = sms.jarque_bera(transformed_data)\n",
    "lzip(name, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try generating more sets of variables and applying other transformations, always inspecting the effect with QQ-plots and/or tests  \n",
    "\n",
    "`x = np.random.normal(0, 1, 500)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Z-scores  \n",
    "`scipy.stats.zscore()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.norm.sf(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe the properties of a Normal Distribution. Then change the mean and std and see what happens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_cdf(mean=0.0, std=1.0):\n",
    "    # 50 numbers between -3σ and 3σ\n",
    "    x = linspace(-3*std, 3*std, 50)\n",
    "    # CDF at these values\n",
    "    y = stats.norm.cdf(x, loc=mean, scale=std)\n",
    "    plt.ylabel(\"Cumulative Probability\")\n",
    "    plt.title(\"Cum. Dist. for Gaussian of mean = {0} | std. dev. = {1}\".format(\n",
    "               mean, std))\n",
    "    plt.plot(x,y, color=\"black\")\n",
    "    plt.xlabel(\"Variate\")\n",
    "    plt.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_cdf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_cdf(mean=3, std=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the percentage of the curve lower than the mean minus 3 deviations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.norm.cdf(-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the percentage of the curve lower than the mean plus 2 sd?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.norm.cdf(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the percentage of the curve ABOVE the mean plus 2 sd?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4 - Inference and hypothesis testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write your own t-test for two independent samples (or an F-test, if you prefer) and calculate the p-value of the statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def a_ttest(x, y):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5 - Effect sizes and Power tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cohens's D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the Cohen's d between two samples\n",
    "from numpy.random import randn\n",
    "from numpy.random import seed\n",
    " \n",
    "# function to calculate Cohen's d for independent samples\n",
    "def cohen_d(d1, d2):\n",
    "    # calculate the size of samples\n",
    "    n1, n2 = len(d1), len(d2)\n",
    "    # calculate the variance of the samples - Which variance (biased or unbiased) is being used here?\n",
    "    s1, s2 = var(d1, ddof=1), var(d2, ddof=1)\n",
    "    # calculate the pooled standard deviation\n",
    "    s = np.sqrt(((n1 - 1) * s1 + (n2 - 1) * s2) / (n1 + n2 - 2))\n",
    "    # calculate the means of the samples\n",
    "    u1, u2 = mean(d1), mean(d2)\n",
    "    # calculate the effect size\n",
    "    return (u1 - u2) / s\n",
    " \n",
    "# seed random number generator\n",
    "seed(1)\n",
    "# prepare data\n",
    "data1 = 10 * randn(10000) + 50\n",
    "data2 = 10 * randn(10000) + 100\n",
    "# calculate cohen's d\n",
    "d = cohend(data1, data2)\n",
    "print('Cohens d: %.3f' % d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POWER tests with *statsmodels*\n",
    "\n",
    "**For a 2-sample test:**\n",
    "\n",
    "\n",
    "`statsmodels.stats.power.tt_ind_solve_power(effect_size=None, nobs1=None, alpha=None, power=None, ratio=1.0, alternative='two-sided')`  \n",
    "\n",
    "\n",
    "Here `effect size` means the standardized effect size, i. e., the diference between the two means divided by the standard deviation.  \n",
    "\n",
    "\n",
    "You can solve for one of the desired parameters `effect_size`, `nobs1`, `alpha`, or `power`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the number of samples required to detect an effect size of 1, given alpha=0.05 and power of 0.8?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power.tt_ind_solve_power(effect_size=1, nobs1=None, alpha=0.05, power=0.80, ratio=1.0, alternative='two-sided')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens if we want to have more power in the test? (increase to 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power.tt_ind_solve_power(effect_size=1, nobs1=None, alpha=0.05, power=0.90, ratio=1.0, alternative='two-sided')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power.tt_ind_solve_power(effect_size=0.5, nobs1=30, alpha=0.05, power=None, ratio=1.0, alternative='two-sided')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RESAMPLING and bootstrap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rewrite the t-test function you created and use bootstrapping to estimate the  p-value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrapped_ttest():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 7 - Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm training a model to predict the daily sales of PARFUM and MAKE_UP.  \n",
    "The overall error (I chose the metric MAE) of the model is 305 orders per day. But when analized the MAE by clusters, I got 270 (s.d.=23) for PARFUM and 338 (s.d.=80) for MAKE-UP. Is this model statistically performing worse for MAKE_UP? How do you answer this question?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get familiar with Statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a list of available built-in datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dir(sm.datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load a dataset as Pandas dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sm.datasets.co2.load_pandas()\n",
    "data.data.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.data.reset_index()\n",
    "df['YEAR'] = pd.to_datetime(df['index']).dt.year\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup and fit the model (simple OLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mod = smf.ols(formula='co2 ~ YEAR', data=df) # Describe a simple univariate linear regression\n",
    "res = mod.fit()                              # Fit model\n",
    "print(res.summary())                         # Summarize model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the CO2 concentration estimated by the model for 1996?  \n",
    "How different is it from the average of that year (hint: use `pd.groupby()`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refit the model after log-transformation of variables.  \n",
    "What changes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.copy()\n",
    "df2['co2'] = np.log10(df2['co2'])\n",
    "df2['YEAR'] = np.log10(df2['YEAR'])\n",
    "\n",
    "mod = smf.ols(formula='co2 ~ YEAR', data=df2) # Describe a simple univariate linear regression\n",
    "res = mod.fit()                              # Fit model\n",
    "print(res.summary()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error metrics\n",
    "What are the appropriate error metrics for the evaluation of this model?\n",
    "How would you calculate them?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
